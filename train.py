import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts
import math
from PIL import Image
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import os
from model import ConvLSTMAutoencoder
import sys
import matplotlib.pyplot as plt
from scipy.spatial import distance_matrix
from torch.utils.data import DataLoader
from dataset_ivf import IVFSequenceDataset
from tqdm import tqdm
from datetime import datetime
torch.backends.cuda.enable_mem_efficient_sdp(False)
torch.backends.cuda.enable_flash_sdp(False)
torch.backends.cuda.enable_math_sdp(True)
batch_size = 50
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
from huggingface_hub import HfApi
import wandb
import gc
gc.collect()
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import os
import time

from huggingface_hub import login
import shutil
import hashlib
import json
from torchsummary import summary
class RunningStats:
    def __init__(self):
        self.n = 0
        self.mean = 0.0
        self.m2 = 0.0

    def push(self, x):
        self.n += 1
        delta = x - self.mean
        self.mean += delta / self.n
        delta2 = x - self.mean
        self.m2 += delta * delta2

    @property
    def variance(self):
        return self.m2 / (self.n - 1) if self.n > 1 else 0.0

    @property
    def std_dev(self):
        return math.sqrt(self.variance)

VAL_EMBRYOS = []#"RS363-7", "CZ594-5","CJ261-10","RL747-8","TM272-9","LFA766-1","GT353-3","LGA881-2-5","LBE649-3","TH481-5","LTA908-2","BS648-7","GS955-7","HA1040-4","CM892-5","FC048-6","GC702-6","DI358-3","MM912-4","RK787-3","GSS052-2","OJ319-5","DML373-2","PS292-4","TM294-2","KT573-4","DJC641-4","FE14-020","LD400-1","MV930-2","MDCH869-4","AS662-2","LH1169-8","GA664-1","PMDPI029-1-3","DV116-3","FV709-11","GM456-3","RA361-4","LM844-1","DL020-3","VM570-4","MC833-6","LV613-2","ZS435-5","RM126-7","BK428-2","LS93-8","GS490-7","GF976-4","PMDPI029-1-11","DRL1048-1","BS294-7","CA658-12","RO793-2","GJ191-1","CC007-2","SL313-11","RC545-2-8","OJ319-9","PA289-8","TK319-10","SM686-7","KJ1077-3","BE645-10","BC167-4","VC581-1","FM162-6","PC758-2","HC459-6","DE069-10","GC340-3","BS596-5","PE256-2","LBE857-1","PH783-3","LS1045-4","CC455-3","DL617-6","BS1086-1","CK601-4","DA309-5","LTE064-1","KF460-4","LP181-1","GS349-4","LC47-8","GS205-6","EH309-8","BS1033-2","LL854-1","DHDPI042-6","BN356-6","PA145-2","GC340-1","MM334-5","AG274-2","BA518-7","BC973-4","BA1195-9","AM33-2","AB91-1","AB028-6","BC167-4","AL884-2","AM685-3"]
def temporal_smoothness_loss(z_seq, weight=0.1):
    if z_seq.size(1) < 2:
        return torch.tensor(0.0, device=z_seq.device)
    
    diff = z_seq[:, 1:] - z_seq[:, :-1]  # (B, T-1, C, H, W)
    smooth_loss = (diff ** 2).mean()
    
    return weight * smooth_loss


def generate_repo_name(mode, config_dict, file_paths, date_str):
    config_str = json.dumps(config_dict, sort_keys=True)

    file_hasher = hashlib.sha256()
    for file_path in file_paths:
        if os.path.exists(file_path):
            with open(file_path, 'rb') as f:
                file_hasher.update(f.read())
        else:
            file_hasher.update(file_path.encode())

    combined_hasher = hashlib.sha256()
    combined_hasher.update(config_str.encode())
    combined_hasher.update(file_hasher.digest())
    combined_hasher.update(date_str.encode())

    short_hash = combined_hasher.hexdigest()[:8]

    repo_name = f"embryo-{mode}-{short_hash}-{date_str}"

    if len(repo_name) > 96:
        max_mode_len = 96 - len(f"embryo--{short_hash}-{date_str}")
        truncated_mode = mode[:max_mode_len]
        repo_name = f"embryo-{truncated_mode}-{short_hash}-{date_str}"

    return repo_name

def save_and_push_model(model, repo_name, required_files, model_config=None):
    os.makedirs(repo_name, exist_ok=True)

    try:
        model.save_pretrained(repo_name)
        print(f"Saved model using save_pretrained")
    except Exception as e:
        print(f"save_pretrained failed ({e}), saving state dict only")
        torch.save(model.state_dict(), os.path.join(repo_name, "pytorch_model.bin"))

    if model_config is not None:
        config_path = os.path.join(repo_name, "config.json")
        with open(config_path, 'w') as f:
            json.dump(model_config, f, indent=2)
        print(f"Saved config.json with ablation parameters")

    for file_path in required_files:
        if os.path.exists(file_path):
            shutil.copy2(file_path, repo_name)
            print(f"Added {file_path} to repository")
        else:
            print(f"Warning: {file_path} not found, skipping")

    try:
        model.push_to_hub(repo_name)
        print(f"Pushed model weights to {repo_name}")
    except Exception as e:
        print(f"Warning: push_to_hub failed ({e}), will upload manually")

    api = HfApi()

    config_file = os.path.join(repo_name, "config.json")
    if os.path.exists(config_file):
        try:
            api.upload_file(
                path_or_fileobj=config_file,
                path_in_repo="config.json",
                repo_id=f"HUGGINGFACE/{repo_name}",
                repo_type="model"
            )
            print(f"Uploaded config.json to HuggingFace Hub")
        except Exception as e:
            print(f"Warning: Failed to upload config.json: {e}")

    
    for file_path in required_files:
        local_file = os.path.join(repo_name, os.path.basename(file_path))
        if os.path.exists(local_file):
            try:
                api.upload_file(
                    path_or_fileobj=local_file,
                    path_in_repo=os.path.basename(file_path),
                    repo_id=f"JensLundsgaard/{repo_name}",
                    repo_type="model"
                )
                print(f"Uploaded {file_path} to HuggingFace Hub")
            except Exception as e:
                print(f"Warning: Failed to upload {file_path}: {e}")
        else:
            print(f"Warning: {local_file} not found, skipping upload")

    print(f"Successfully pushed all files to {repo_name}")
def gaussian_kernel(size=11, sigma=1.5):
    coords = torch.arange(size, dtype=torch.float32)
    coords -= size // 2
    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
    g /= g.sum()
    return g.unsqueeze(0) * g.unsqueeze(1)


def ssim(img1, img2, kernel_size=11, sigma=1.5, C1=0.01**2, C2=0.03**2):
    kernel = gaussian_kernel(kernel_size, sigma).to(img1.device)
    kernel = kernel.unsqueeze(0).unsqueeze(0)  # (1, 1, k, k)
    
    mu1 = F.conv2d(img1, kernel, padding=kernel_size//2)
    mu2 = F.conv2d(img2, kernel, padding=kernel_size//2)
    
    mu1_sq = mu1 ** 2
    mu2_sq = mu2 ** 2
    mu1_mu2 = mu1 * mu2
    
    sigma1_sq = F.conv2d(img1 * img1, kernel, padding=kernel_size//2) - mu1_sq
    sigma2_sq = F.conv2d(img2 * img2, kernel, padding=kernel_size//2) - mu2_sq
    sigma12 = F.conv2d(img1 * img2, kernel, padding=kernel_size//2) - mu1_mu2
    
    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \
               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
    
    return ssim_map.mean()

# this and above as defined by Wang et al. 10.1109/ACSSC.2003.1292216
def ms_ssim(img1, img2, kernel_size=11, sigma=1.5, weights=None, levels=5):
    if weights is None:
        weights = torch.tensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333],
                              device=img1.device)[:levels]
    
    kernel = gaussian_kernel(kernel_size, sigma).to(img1.device)
    kernel = kernel.unsqueeze(0).unsqueeze(0).repeat(img1.shape[1], 1, 1, 1)
    
    mcs_list = []
    
    for i in range(levels):
        if i == levels - 1:
            ssim_val = ssim(img1, img2, kernel_size, sigma)
        else:
            # Compute CS (contrast-structure) only
            mu1 = F.conv2d(img1, kernel, padding=kernel_size//2, groups=img1.shape[1])
            mu2 = F.conv2d(img2, kernel, padding=kernel_size//2, groups=img1.shape[1])
            
            sigma1_sq = F.conv2d(img1**2, kernel, padding=kernel_size//2, groups=img1.shape[1]) - mu1**2
            sigma2_sq = F.conv2d(img2**2, kernel, padding=kernel_size//2, groups=img1.shape[1]) - mu2**2
            sigma12 = F.conv2d(img1*img2, kernel, padding=kernel_size//2, groups=img1.shape[1]) - mu1*mu2
            
            C2 = 0.03**2
            cs = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)
            mcs_list.append(cs.mean())
            
            img1 = F.avg_pool2d(img1, 2)
            img2 = F.avg_pool2d(img2, 2)
    
    ms_ssim_val = torch.prod(torch.stack([mcs ** w for mcs, w in zip(mcs_list, weights[:-1])]))
    ms_ssim_val = (ssim_val ** weights[-1]) * ms_ssim_val
    
    return ms_ssim_val

def reconstruction_loss(x_rec, x_true, l1_weight=0.5, ms_ssim_weight=0.5):
    B, T, C, H, W = x_rec.shape
    
    x_rec_flat = x_rec.view(B * T, C, H, W)  # (B*T, 1, 128, 128)
    x_true_flat = x_true.view(B * T, C, H, W)  # (B*T, 1, 128, 128)
    
    l1_loss = F.l1_loss(x_rec, x_true)
    
    ms_ssim_val = ms_ssim(x_rec_flat, x_true_flat)
    ms_ssim_loss = 1 - ms_ssim_val
    
    total_loss = l1_weight * l1_loss + ms_ssim_weight * ms_ssim_loss
    
    return total_loss, {
        "l1_loss": l1_loss.item(),
        "ms_ssim_loss": ms_ssim_loss.item(),
        "ms_ssim_value": ms_ssim_val.item()
    }


def train_convlstm(
    loss_type="l1",
    ms_ssim_weight=0.5,
    rec_weight=0.5,
    temporal_weight=0.1,
    dropout_rate=0.1,
    use_convlstm=True,
    use_residual=True,
    use_batchnorm=True,
    model_name="", 
    latent_size = 4096
):
    gc.collect()

    print(torch.cuda.memory_summary(device=None, abbreviated=False))
    torch.cuda.empty_cache()
    torch.autograd.detect_anomaly(True)
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    VAL_EMBRYOS = pd.read_csv("embryo_dataset_grades.csv").rename(columns={"video_name":"embryo_id"}).dropna(subset=["ICM"])["embryo_id"].astype(str).tolist()
    # Build loss description for logging
    loss_components = []
    if ms_ssim_weight > 0:
        loss_components.append(f"MS-SSIM({ms_ssim_weight})")
    if rec_weight > 0:
        loss_components.append(f"{loss_type.upper()}({rec_weight})")
    if temporal_weight > 0:
        loss_components.append(f"Temporal({temporal_weight})")
    loss_description = " + ".join(loss_components) if loss_components else "None"

    # Build model description for logging
    model_features = []
    if use_convlstm:
        model_features.append("ConvLSTM")
    if use_residual:
        model_features.append("Residual")
    if use_batchnorm:
        model_features.append("BatchNorm")
    if dropout_rate > 0:
        model_features.append(f"Dropout({dropout_rate})")
    model_description = "+".join(model_features) if model_features else "Baseline"
    date_label = datetime.now().strftime("%Y-%m-%d")

    wandb.login(key=os.getenv("WANDB_KEY"))
    run = wandb.init(
        entity="WANDB",
        project="IVF-Training",
        name=model_name +"-" + date_label,
        config={
            "learning_rate": 0.02,
            "architecture": "ConvLSTM Autoencoder",
            "model_features": model_description,
            "dataset": "https://zenodo.org/records/7912264",
            "epochs": 10,
            "train_split": 0.85,
            "val_split": 0.15,
            "loss": loss_description,
            "loss_type": loss_type,
            "ms_ssim_weight": ms_ssim_weight,
            "rec_weight": rec_weight,
            "temporal_weight": temporal_weight,
            "dropout_rate": dropout_rate,
            "use_convlstm": use_convlstm,
            "use_residual": use_residual,
            "use_batchnorm": use_batchnorm,
            "latent_size": latent_size,
            "seq_len": 50,
            "image_size": 128,
            "distributed": False,
        },
    )

    login(os.getenv("HF_KEY"))
    print(torch.cuda.memory_summary(device=None, abbreviated=False))
    print(DEVICE)
        # Save detailed training configuration
    config_content = f"""ConvLSTM Autoencoder Training Configuration (ABLATION)"""

    with open("training_config_detailed.txt", "w") as f:
        f.write(config_content)

    print("Configuration saved to training_config_detailed.txt")

    model = ConvLSTMAutoencoder(
        None,
        seq_len=50,
        input_channels=1,
        encoder_hidden_dim=256,
        encoder_layers=2,
        decoder_hidden_dim=128,
        decoder_layers=2,
        latent_size=latent_size,
        use_classifier=False,
        num_classes=2,
        use_latent_split=False,
        dropout_rate=dropout_rate,
        use_convlstm=use_convlstm,
        use_residual=use_residual,
        use_batchnorm=use_batchnorm
    )

    model = model.to(DEVICE)
    trainable_params = 0
    all_params = 0
    for _, param in model.named_parameters():
        all_params += param.numel()
        if param.requires_grad:
            trainable_params += param.numel()
    print(
        f"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params / all_params}"
    )
    run.log({"train_params":trainable_params})
    run.log({"params":all_params})
    learning_rate = 2e-4
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)

    df = pd.read_csv(os.path.abspath("index.csv"))
    mask = df["cell_id"].str.contains("|".join(VAL_EMBRYOS), regex=True)
    val_df = df[mask]
    train_df = df[~mask]
    train_dataset = IVFSequenceDataset(train_df, resize=128, norm="minmax01")
    val_dataset = IVFSequenceDataset(val_df, resize=128, norm="minmax01")
    print("val size: ", str(len(val_df) / len(df)))

    #generator = torch.Generator().manual_seed(42)
    #train_dataset, val_dataset = torch.utils.data.random_split(ds, [train_size, val_size], generator=generator)

    # Create DataLoaders
    loader = DataLoader(
        train_dataset,
        batch_size=64,
        shuffle=True,
        num_workers=16,
        pin_memory=True,
        drop_last=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=1,
        shuffle=False,  # No shuffle for validation
        num_workers=16,
        pin_memory=True,
        drop_last=False  # Don't drop last for validation
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(loader) * 10)

    for epoch in range(10):
        model.train()
        pbar = tqdm(loader, desc=f"epoch {epoch}")
        total = 0.0
        count = 0
        start_time = time.perf_counter()
        end_time = time.perf_counter()
        for index, (embryo_vol, _, _) in enumerate(pbar):
            optimizer.zero_grad()

            embryo_vol = embryo_vol.to(DEVICE)  # (1, T, 1, 500, 500)

            # Forward pass - returns (reconstruction, latent_seq)
            embryo_recon, embryo_lat = model(embryo_vol)
            if(index % 47 == 0):
                vol_img = embryo_vol[0, -1, 0].cpu().detach().numpy()
                recon_img = embryo_recon[0, -1, 0].cpu().detach().numpy()

                vol_img = (vol_img * 255).astype(np.uint8)
                recon_img = (recon_img * 255).astype(np.uint8)
                comparison = np.concatenate((vol_img, recon_img), axis=1)
     
                images = wandb.Image(comparison, caption="Embryo vs Recon comparison")
                run.log({"reconstruction": images})
                traj = embryo_lat.cpu().detach().numpy()[0]
                dist_matrix = distance_matrix(traj, traj)
                fig, ax = plt.subplots(figsize=(8, 6))
                im = ax.imshow(dist_matrix, cmap='viridis')

                ax.set_xlabel("Time Index")
                ax.set_ylabel("Time Index")
                plt.colorbar(im, ax=ax)
                wandb.log({"temp_smoothness": wandb.Image(fig)})

                plt.close(fig)
            # Reconstruction loss using MS-SSIM + L1 or MSE (with configurable weights)
            if loss_type == "l1":
                rec_loss, rec_metrics = reconstruction_loss(
                    embryo_recon, embryo_vol, l1_weight=rec_weight, ms_ssim_weight=ms_ssim_weight
                )
            elif loss_type == "mse":
                # MS-SSIM + MSE loss
                B, T, C, H, W = embryo_recon.shape
                x_rec_flat = embryo_recon.view(B * T, C, H, W)
                x_true_flat = embryo_vol.view(B * T, C, H, W)

                mse_loss = F.mse_loss(embryo_recon, embryo_vol)
                ms_ssim_val = ms_ssim(x_rec_flat, x_true_flat)
                ms_ssim_loss = 1 - ms_ssim_val

                rec_loss = rec_weight * mse_loss + ms_ssim_weight * ms_ssim_loss
                rec_metrics = {
                    "mse_loss": mse_loss.item(),
                    "ms_ssim_loss": ms_ssim_loss.item(),
                    "ms_ssim_value": ms_ssim_val.item()
                }
            else:
                raise ValueError(f"Invalid loss_type: {loss_type}. Must be 'l1' or 'mse'")

            if temporal_weight > 0:
                smooth_loss = temporal_smoothness_loss(embryo_lat, weight=temporal_weight)
                loss = rec_loss + smooth_loss
            else:
                smooth_loss = torch.tensor(0.0, device=DEVICE)
                loss = rec_loss

            if torch.isnan(loss) or torch.isinf(loss):
                print(f"NaN/Inf detected, skipping batch")
                continue

            loss.backward()
            total_norm = 0
            for p in model.parameters():
                if p.grad is not None:
                    param_norm = p.grad.data.norm(2)
                    total_norm += param_norm.item() ** 2
            total_norm = total_norm ** 0.5

            if total_norm > 100:
                print(f"Warning: Large gradient norm: {total_norm:.2f}")

            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)
            scheduler.step()
            optimizer.step()
            end_time = time.perf_counter()

            
            total += loss.item()
            count += 1

            if (index % 50 == 0) and run is not None:
                log_dict = {
                    "step": epoch * len(loader) + index,
                    "loss": loss.item(),
                    "rec_loss": rec_loss.item(),
                    "smooth_loss": smooth_loss.item(),
                    "ms_ssim": rec_metrics["ms_ssim_value"],
                    "lr": scheduler.get_last_lr()[0]
                }

                # Add loss-specific metrics
                if loss_type == "l1":
                    log_dict["l1_loss"] = rec_metrics["l1_loss"]
                elif loss_type == "mse":
                    log_dict["mse_loss"] = rec_metrics["mse_loss"]

                run.log(log_dict)

                pbar.set_postfix(
                    loss=f"{loss.item():.4f}",
                    rec=f"{rec_loss.item():.4f}",
                    smooth=f"{smooth_loss.item():.4f}"
                )


        duration = end_time - start_time
        print(f"Duration: {duration}")
        run.log({"epoch_time":duration})
        avg_loss = total/max(1, count)
        run.log({"avg_loss": avg_loss})
        print(f"epoch {epoch} avg loss={avg_loss:.4f}")

        # Save the state dict
        torch.save(model.state_dict(), "convlstm_model_weights.pth")

        # Generate unique repo name based on config and code
        date_label = datetime.now().strftime("%Y-%m-%d")

        # Collect all config for hashing
        config_for_hash = {
            "mode": "convlstm",
            "loss_type": loss_type,
            "ms_ssim_weight": ms_ssim_weight,
            "rec_weight": rec_weight,
            "temporal_weight": temporal_weight,
            "dropout_rate": dropout_rate,
            "use_convlstm": use_convlstm,
            "use_residual": use_residual,
            "use_batchnorm": use_batchnorm,
            "learning_rate": 2e-4,
            "encoder_hidden_dim": 256,
            "encoder_layers": 2,
            "decoder_hidden_dim": 128,
            "decoder_layers": 2,
            "latent_size": latent_size,
            "seq_len": 50,
            "image_size": 128,
        }

        # Required files for ConvLSTM model
        required_files = [
            "train.py",
            "raffael_model.py",
            "raffael_losses.py",
            "raffael_conv_lstm.py",
            "dataset_ivf.py",
            "train_model.sh",
            "training_config.txt",
            "training_config_detailed.txt",
        ]

        # Generate unique repo name
        repo_name = generate_repo_name("convlstm", config_for_hash, required_files, date_label)

        # Create comprehensive config for HuggingFace
        hf_config = {
            "model_type": "ConvLSTMAutoencoder",
            "architecture": "ConvLSTM Autoencoder",
            # Model architecture parameters
            "seq_len": 50,
            "input_channels": 1,
            "encoder_hidden_dim": 256,
            "encoder_layers": 2,
            "decoder_hidden_dim": 128,
            "decoder_layers": 2,
            "latent_size": latent_size,
            "use_classifier": False,
            "num_classes": 2,
            "use_latent_split": False,
            "image_size": 128,
            # Ablation parameters
            "dropout_rate": dropout_rate,
            "use_convlstm": use_convlstm,
            "use_residual": use_residual,
            "use_batchnorm": use_batchnorm,
            # Loss configuration
            "loss_type": loss_type,
            "ms_ssim_weight": ms_ssim_weight,
            "rec_weight": rec_weight,
            "temporal_weight": temporal_weight,
            "loss_description": loss_description,
            # Training configuration
            "learning_rate": 2e-4,
            "weight_decay": 1e-5,
            "optimizer": "Adam",
            "scheduler": "CosineAnnealingLR",
            "batch_size": 1,
            "epochs": 10,
            "gradient_clip": 5.0,
            # Dataset
            "dataset": "https://zenodo.org/records/7912264",
            "resize": 128,
            "normalization": "minmax01",
            # Reproducibility
            "repo_name": repo_name,
            "date": date_label,
            "hash": repo_name.split("-")[-2] if "-" in repo_name else "",
        }

        save_and_push_model(model, model_name +"-"+ date_label, required_files, model_config=hf_config)
        val_metrics = {
            'mse': RunningStats(),
            'l1': RunningStats(),
            'ssim': RunningStats(),
            'temp': RunningStats()
        }
        model.eval()  # Set model to evaluation mode
        with torch.no_grad():
            for embryo_vol, _, _ in val_loader:
                embryo_vol = embryo_vol.to(DEVICE)  # (1, T, 1, H, W)
                val_recon, val_lat = model(embryo_vol)
                B, T, C, H, W = embryo_vol.shape

                # MSE
                val_metrics['mse'].push(F.mse_loss(val_recon, embryo_vol).item())

                # L1
                val_metrics['l1'].push(F.l1_loss(val_recon, embryo_vol).item())

                # MS-SSIM
                val_recon_flat = val_recon.view(B * T, C, H, W)
                embryo_vol_flat = embryo_vol.view(B * T, C, H, W)
                ms_ssim_val = ms_ssim(val_recon_flat, embryo_vol_flat)
                val_metrics['ssim'].push((1 - ms_ssim_val).item())

                # Temporal smoothness of latents
                # val_lat is (B, T, latent_size)
                if T > 1:
                    val_metrics['temp'].push(temporal_smoothness_loss(val_lat).item())
        # Log to wandb with val_ prefix
        val_log_dict = {
            f"val_{key}": value.mean for key, value in val_metrics.items()
        }
        val_log_std_dict = {
            f"val_{key}_std": value.std_dev for key, value in val_metrics.items()
        }

        run.log(val_log_dict)
        run.log(val_log_std_dict)
        

    run.finish()
    gc.collect()
    torch.cuda.empty_cache()



if __name__ == "__main__":
    import sys
    import argparse

    parser = argparse.ArgumentParser(description="Train ConvLSTM Autoencoder with Ablation Studies")
    parser.add_argument("mode", type=str, help="Training mode")

    parser.add_argument("--loss-type", type=str, default="l1", choices=["l1", "mse"],
                      help="Reconstruction loss type: l1 or mse (default: l1)")
    parser.add_argument("--ms-ssim-weight", type=float, default=0.5,
                      help="Weight for MS-SSIM loss (default: 0.5, set to 0 to disable)")
    parser.add_argument("--rec-weight", type=float, default=0.5,
                      help="Weight for reconstruction loss (default: 0.5, set to 0 to disable)")
    parser.add_argument("--temporal-weight", type=float, default=0.1,
                      help="Weight for temporal smoothness loss (default: 0.1, set to 0 to disable)")

    parser.add_argument("--dropout-rate", type=float, default=0.1,
                      help="Dropout rate (default: 0.1, set to 0 to disable)")
    parser.add_argument("--no-convlstm", action="store_true",
                      help="Disable ConvLSTM (no temporal modeling)")
    parser.add_argument("--no-residual", action="store_true",
                      help="Disable residual connections")
    parser.add_argument("--no-batchnorm", action="store_true",
                      help="Disable batch normalization")
    parser.add_argument("--name", type=str, default="", help="model name duhh")
    parser.add_argument("--size", type=int, default=4096, help="lat size bruh")
    args = parser.parse_args()

    train_convlstm(
        loss_type=args.loss_type,
        ms_ssim_weight=args.ms_ssim_weight,
        rec_weight=args.rec_weight,
        temporal_weight=args.temporal_weight,
        dropout_rate=args.dropout_rate,
        use_convlstm=not args.no_convlstm,
        use_residual=not args.no_residual,
        use_batchnorm=not args.no_batchnorm,
        model_name = args.name,
        latent_size = args.size

    )
